# -*- coding: utf-8 -*-
"""Copy of Untitled4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1x-dVgCtAbV43iS_7iAhQa_-sw3HD14qz

#@Assignment three

Importing Libraries
"""



import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

"""Import the CSV"""

df = pd.read_csv('./Train_data.csv')
test_data = pd.read_csv('./Test_data.csv')



"""EDA """

test_data.describe()

test_data.head()

test_data.info()

jobs = pd.get_dummies(test_data['job_type'])

days_passed_null = test_data['days_passed'] == -1
days_passed_null.value_counts()

#@title
pred = pd.get_dummies(test_data['Outcome'])
pred

sns.scatterplot(data = test_data , y = 'Outcome' , x = 'days_passed')
plt

edu = pd.get_dummies(test_data['education_level'])
test_data['education_level'].isnull().value_counts()

df1 = pd.concat(objs = [pred, edu], axis=1)
ax = sns.heatmap(df1.corr(), annot=True)

marital_dummies = pd.get_dummies(test_data['marital_status'])
marital_dummies

test_data['communication'].head(10)

imp_mode = SimpleImputer(missing_values=np.nan, strategy='most_frequent')

test_data['education_level'] = imp_mode.fit_transform(test_data[['education_level']])

test_data['education_level'].isnull().value_counts()

imp_mode = SimpleImputer(missing_values=np.nan, strategy='most_frequent')
test_data['communication']= imp_mode.fit_transform(test_data[['communication']])
test_data['communication'].isnull().value_counts()

imp_mode = SimpleImputer(missing_values=np.nan, strategy='most_frequent')
test_data['job_type']= imp_mode.fit_transform(test_data[['job_type']])
test_data['job_type'].isnull().value_counts()

test_data.info()

test_data['Outcome'].isnull().value_counts()

df.info()

df = df.drop(columns=['Outcome'])
df.head()

df.info()

df['education_level'] = imp_mode.fit_transform(df[['education_level']])

df['education_level'].isnull().value_counts()

imp_mode = SimpleImputer(missing_values=np.nan, strategy='most_frequent')
df['communication']= imp_mode.fit_transform(df[['communication']])
df['communication'].isnull().value_counts()

imp_mode = SimpleImputer(missing_values=np.nan, strategy='most_frequent')
df['job_type']= imp_mode.fit_transform(df[['job_type']])
df['job_type'].isnull().value_counts()

df.head(10)

edu = pd.get_dummies(df['education_level'])
marital = pd.get_dummies(df['marital_status'])
job = pd.get_dummies(df['job_type'])

edu_df = pd.DataFrame(edu)
mar_df = pd.DataFrame(marital)
job_df = pd.DataFrame(job)
job_df.head()

df.head()

dum = pd.concat([edu_df, job_df, mar_df], axis=1)

# df = pd.concat([df, dum], axis=1)
df.head()

df = df.drop(columns= ['days_passed'])
df.head()

df = df.drop(columns= ['call_start', 'call_end'])
df.head()

df = df.drop(columns= ['last_contact_day', 'last_contact_month'])
df.head()

df.head(10)

df = df.drop(columns= ['job_type', 'marital_status', 'education_level'])
df.head()

test_data.head()

test_data = test_data.drop(columns= ['last_contact_day', 'last_contact_month', 'days_passed'])
test_data.head()

test_data = test_data.drop(columns= ['Outcome', 'call_start','call_end'])
test_data.head()

educate_dum = pd.get_dummies(test_data['education_level'])
job_dum = pd.get_dummies(test_data['job_type'])
marital_dum = pd.get_dummies(test_data['marital_status'])

edu_df = pd.DataFrame(educate_dum)
jobDum_df = pd.DataFrame(job_dum)
marital_df = pd.DataFrame(marital_dum)

test_dum = pd.concat([edu_df, jobDum_df, marital_df], axis=1)
test_dum.head()

test_data = pd.concat([test_data, test_dum], axis=1)
test_data.head()

test_data = test_data.drop(['marital_status', 'job_type', 'education_level'], axis=1)

test_data.head()

X = df.drop(['car_insurance'], axis=1)
y = df['car_insurance']

y.head()

comm_dum = pd.get_dummies(df.communication)

comm = pd.DataFrame(comm_dum)

df = pd.concat([df, comm], axis=1)
df = df.drop(['communication'], axis=1)
df.head()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)

# sc = StandardScaler()
# X_test = sc.fit_transform(X_test)
# X_train = sc.fit_transform(X_train)

classifier = RandomForestClassifier(n_estimators=10, random_state=0)
classifier.fit(X_train, y_train)
y_pred = classifier.predict(X_test)

clf = DecisionTreeClassifier(random_state=42, max_depth=10 )

clf.fit(X_train, y_train)
y_dtpred = clf.predict(X_test)
print(accuracy_score(y_test, y_pred))

print(accuracy_score(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

pred_df = pd.DataFrame({'prediction': y_pred[0:935]})

pred_df.to_csv(index = False)